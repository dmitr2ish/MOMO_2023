import numpy as np
# Линейная регрессия. Градиентный спуск.

# Предположим, что у вас есть вектор весов  b= {10,5,6}.
# Вы посчитали градиент функции потерь, который равен  L(b)'= {20,-10,40}.
# Посчитайте обновленный вектор весов при условии, что скорость обучения  составляет 0.1.
# Ответы округлите до целых.

# Что такое градиентный спуск

# Градиентный спуск — это итеративный метод оптимизации, используемый для минимизации функции потерь в машинном обучении и статистике.
# Основная идея состоит в том, чтобы обновлять каждый вес в направлении уменьшения функции потерь.
# В контексте линейной регрессии веса модели обновляются следующим образом:
# b new = b old - α * L(b)'

# где
# b new — обновленный вектор весов,
# b old — текущий вектор весов,
# α — скорость обучения (learning rate),
# L(b)'— градиент функции потерь по вектору весов.

# Таким образом, для обновления вектора весов, нам нужно выполнить следующие шаги для каждого элемента вектора весов:

# Умножить градиент функции потерь на скорость обучения.
# Вычесть полученное значение из текущего вектора весов.

# Текущий вектор весов
b_old = np.array([10, 5, 6])

# Градиент функции потерь
grad_L = np.array([20, -10, 40])

# Скорость обучения
alpha = 0.1

# Обновление вектора весов
b_new = b_old - alpha * grad_L

# Округление до целых чисел
b_new_rounded = np.round(b_new).astype(int)

print(b_new_rounded)
